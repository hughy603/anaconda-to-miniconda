name: Performance Benchmarking

on:
  push:
    branches: [master, develop]
  pull_request:
    branches: [master, develop]
  schedule:
    - cron: '0 0 * * 1'  # Run weekly on Monday
  workflow_dispatch:  # Allow manual triggering

env:
  PYTHON_VERSION: "3.11"
  UV_VERSION: "0.7.1"

jobs:
  benchmark:
    name: Run Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-benchmark
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Run benchmarks
        id: run-benchmarks
        continue-on-error: true
        run: |
          mkdir -p tests/benchmarks
          if [ -d "tests/benchmarks" ]; then
            python -m pytest tests/benchmarks/ --benchmark-json=benchmark-results.json || echo "::warning::Benchmarks failed to run"
          else
            echo "::warning::No benchmark tests found in tests/benchmarks/"
            exit 0
          fi

      - name: Upload benchmark results
        if: always() && steps.run-benchmarks.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results.json
          retention-days: 90

      - name: Show benchmark results
        if: always() && steps.run-benchmarks.outcome == 'success'
        run: |
          if [ -f benchmark-results.json ]; then
            echo "Benchmark Results:"
            cat benchmark-results.json
          else
            echo "::warning::No benchmark results file found"
          fi
